{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from pathlib import Path\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_trump=pd.read_csv('./tweet_data/trump.csv',engine='python')\n",
    "#tweets_biden=pd.read_csv('./tweet_data/biden.csv')\n",
    "#tjb=tweets_biden.dropna(subset=['lat','long','city','state','user_location'],how='all')\n",
    "#tdt=tweets_trump.dropna(subset=['lat','long','city','state','user_location'],how='all')\n",
    "#tjb=tjb.loc[(tjb['country']==\"United States\" ) | (tjb['country']==\"United States of America\")]\n",
    "#tdt=tdt.loc[(tdt['country']==\"United States\" ) | (tdt['country']==\"United States of America\")]\n",
    "#photon_url=\"http://localhost:2322/api?q=\"\n",
    "#photon_reverse=\"http://localhost:2322/reverse?\"\n",
    "\n",
    "#tjb['query_url']=pd.NA\n",
    "#for x in tjb.index:\n",
    "#    if pd.notna(tjb.loc[x,'lat']) and pd.notna(tjb.loc[x,'long']):\n",
    "#        tjb.loc[x,'query_url']=photon_reverse+'lat='+str(tjb.loc[x,'lat'])+'&'+'lon='+str(tjb.loc[x,'long'])\n",
    "#    elif pd.notna(tjb.loc[x,'city']) and pd.notna(tjb.loc[x,'state']):\n",
    "#        tjb.loc[x,'query_url']=photon_url+ tjb.loc[x,'city']+ ' ' + tjb.loc[x,'state']\n",
    "#    else:\n",
    "#        tjb.loc[x,'query_url']=photon_url+str(tjb.loc[x,'user_location'])\n",
    "#tjb['county']=pd.NA\n",
    "#i=0\n",
    "#j=0\n",
    "#for x in tjb.index:\n",
    "#    try:\n",
    "#        photon_response=requests.get(tjb.loc[x,'query_url']).json()['features'][0]['properties']['county']\n",
    "        #j=j+1\n",
    "#    except:\n",
    "#        photon_response=pd.NA\n",
    "#    tjb.loc[x,'county'] = photon_response\n",
    "    #i=i+1\n",
    "    #print(i,j)\n",
    "    #tdt['query_url']=pd.NA\n",
    "#for x in tdt.index:\n",
    "#    if pd.notna(tdt.loc[x,'lat']) and pd.notna(tdt.loc[x,'long']):\n",
    "#        tdt.loc[x,'query_url']=photon_reverse+'lat='+str(tdt.loc[x,'lat'])+'&'+'lon='+str(tdt.loc[x,'long'])\n",
    "#    elif pd.notna(tjb.loc[x,'city']) and pd.notna(tdt.loc[x,'state']):\n",
    "#        tdt.loc[x,'query_url']=photon_url+ tdt.loc[x,'city']+ ' ' + tdt.loc[x,'state']\n",
    "#    else:\n",
    "#        tdt.loc[x,'query_url']=photon_url+str(tdt.loc[x,'user_location'])\n",
    "#tdt['county']=pd.NA\n",
    "#i=0\n",
    "#j=0\n",
    "#for x in tdt.index:\n",
    "#    try:\n",
    "#        photon_response=requests.get(tdt.loc[x,'query_url']).json()['features'][0]['properties']['county']\n",
    "#        j=j+1\n",
    "#    except:\n",
    "#        photon_response=pd.NA\n",
    "#    tdt.loc[x,'county'] = photon_response\n",
    "#    i=i+1\n",
    "#    print(i,j)\n",
    "#filepath=Path('./tweet_data/biden_countied.csv')\n",
    "#tjb.to_csv(filepath)\n",
    "#filepath=Path('./tweet_data/trump_countied.csv')\n",
    "#tdt.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the files\n",
    "#tweets_biden=pd.read_csv('./tweet_data/biden_countied.csv')\n",
    "#tweets_trump=pd.read_csv('./tweet_data/trump_countied.csv')\n",
    "#Only consider those with a valid county and cut down on not needed columns\n",
    "#valid_tweets_b=tweets_biden.dropna(subset=['county']).drop(axis=1,labels=['lat','long','city','country','continent','state','collected_at','user_screen_name','user_name','source','tweet_id','query_url','user_join_date','Unnamed: 0'])\n",
    "#valid_tweets_t=tweets_trump.dropna(subset=['county']).drop(axis=1,labels=['lat','long','city','country','continent','state','collected_at','user_screen_name','user_name','source','tweet_id','query_url','user_join_date','Unnamed: 0'])\n",
    "#valid_tweets=pd.concat([valid_tweets_b,valid_tweets_t], ignore_index=True)\n",
    "#valid_tweets.to_csv('./tweet_data/valid_tweets.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is some boilerplate code to cleanup and name the dataset from census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics=pd.read_csv('./demographics/demographics.csv')\n",
    "tmp_in=pd.Series(range(1,39)).apply(str).apply(lambda x:x.zfill(3))\n",
    "columns_to_drop1=[x+y+z for x in ('S0101_C'+pd.Series(['02','04','05','06'])+'_') for y in tmp_in for z in ['E','M']]\n",
    "columns_to_drop2=[x+y+z for x in ('S0101_C'+pd.Series(['01','03'])+'_') for y in tmp_in for z in ['M']]\n",
    "a=list(range(20,39))\n",
    "a.remove(23)\n",
    "ttmp_in=pd.Series(a).apply(str).apply(lambda x:x.zfill(3))\n",
    "columns_to_drop3=[x+y+z for x in ('S0101_C'+pd.Series(['01','03'])+'_') for y in ttmp_in for z in ['E']]\n",
    "columns_to_drop=columns_to_drop1+columns_to_drop2+columns_to_drop3+['Unnamed: 458']\n",
    "#S0101_C01_023E\n",
    "#().apply(lambda x:x+tmp_in+'E')\n",
    "demographics=demographics.drop(axis=1,labels=columns_to_drop)\n",
    "def convert_column_names(x):\n",
    "    x_split = x.split('_')\n",
    "    if x == 'S0101_C01_023E':\n",
    "        return 'pop_18_24'\n",
    "    if len(x_split)!=3:\n",
    "        return x\n",
    "    if x_split[1]=='C01':\n",
    "        i=int(x_split[2][:-1])\n",
    "        if i==1:\n",
    "            return 'total_pop'\n",
    "        return 'pop_'+str((i-2)*5)+'_'+str((i-1)*5)\n",
    "    if x_split[1]=='C03':\n",
    "        i=int(x_split[2][:-1])\n",
    "        if i==1:\n",
    "            return 'total_male_pop'\n",
    "        return 'pop_male_'+str((i-2)*5)+'_'+str((i-1)*5)\n",
    "    \n",
    "demographics.rename(axis=1,mapper=convert_column_names,inplace=True)\n",
    "demographics=demographics.loc[1:,]\n",
    "demographics.to_csv('./demographics/demographics_cleaned.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>pop_0_5</th>\n",
       "      <th>pop_5_10</th>\n",
       "      <th>pop_10_15</th>\n",
       "      <th>pop_15_20</th>\n",
       "      <th>pop_20_25</th>\n",
       "      <th>pop_25_30</th>\n",
       "      <th>pop_30_35</th>\n",
       "      <th>...</th>\n",
       "      <th>pop_male_45_50</th>\n",
       "      <th>pop_male_50_55</th>\n",
       "      <th>pop_male_55_60</th>\n",
       "      <th>pop_male_60_65</th>\n",
       "      <th>pop_male_65_70</th>\n",
       "      <th>pop_male_70_75</th>\n",
       "      <th>pop_male_75_80</th>\n",
       "      <th>pop_male_80_85</th>\n",
       "      <th>pop_male_85_90</th>\n",
       "      <th>pop_male_105_110</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0500000US01003</td>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>223234</td>\n",
       "      <td>10616</td>\n",
       "      <td>12826</td>\n",
       "      <td>14373</td>\n",
       "      <td>14410</td>\n",
       "      <td>11292</td>\n",
       "      <td>11807</td>\n",
       "      <td>12594</td>\n",
       "      <td>...</td>\n",
       "      <td>6458</td>\n",
       "      <td>6270</td>\n",
       "      <td>7620</td>\n",
       "      <td>7644</td>\n",
       "      <td>6084</td>\n",
       "      <td>7170</td>\n",
       "      <td>3677</td>\n",
       "      <td>2851</td>\n",
       "      <td>1791</td>\n",
       "      <td>8068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0500000US01015</td>\n",
       "      <td>Calhoun County, Alabama</td>\n",
       "      <td>113605</td>\n",
       "      <td>6699</td>\n",
       "      <td>5534</td>\n",
       "      <td>7774</td>\n",
       "      <td>7541</td>\n",
       "      <td>6973</td>\n",
       "      <td>7088</td>\n",
       "      <td>7893</td>\n",
       "      <td>...</td>\n",
       "      <td>3160</td>\n",
       "      <td>3032</td>\n",
       "      <td>3164</td>\n",
       "      <td>4281</td>\n",
       "      <td>2683</td>\n",
       "      <td>2658</td>\n",
       "      <td>1541</td>\n",
       "      <td>960</td>\n",
       "      <td>901</td>\n",
       "      <td>4245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0500000US01043</td>\n",
       "      <td>Cullman County, Alabama</td>\n",
       "      <td>83768</td>\n",
       "      <td>5310</td>\n",
       "      <td>4563</td>\n",
       "      <td>5906</td>\n",
       "      <td>4591</td>\n",
       "      <td>4603</td>\n",
       "      <td>5402</td>\n",
       "      <td>5186</td>\n",
       "      <td>...</td>\n",
       "      <td>2889</td>\n",
       "      <td>2662</td>\n",
       "      <td>2279</td>\n",
       "      <td>3170</td>\n",
       "      <td>1673</td>\n",
       "      <td>2596</td>\n",
       "      <td>1411</td>\n",
       "      <td>593</td>\n",
       "      <td>661</td>\n",
       "      <td>2962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0500000US01049</td>\n",
       "      <td>DeKalb County, Alabama</td>\n",
       "      <td>71513</td>\n",
       "      <td>4578</td>\n",
       "      <td>4292</td>\n",
       "      <td>5519</td>\n",
       "      <td>5128</td>\n",
       "      <td>4989</td>\n",
       "      <td>4281</td>\n",
       "      <td>4155</td>\n",
       "      <td>...</td>\n",
       "      <td>2185</td>\n",
       "      <td>2203</td>\n",
       "      <td>2011</td>\n",
       "      <td>2388</td>\n",
       "      <td>2080</td>\n",
       "      <td>1281</td>\n",
       "      <td>1476</td>\n",
       "      <td>437</td>\n",
       "      <td>85</td>\n",
       "      <td>3956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0500000US01051</td>\n",
       "      <td>Elmore County, Alabama</td>\n",
       "      <td>81209</td>\n",
       "      <td>4272</td>\n",
       "      <td>6638</td>\n",
       "      <td>3812</td>\n",
       "      <td>4896</td>\n",
       "      <td>4038</td>\n",
       "      <td>6165</td>\n",
       "      <td>6956</td>\n",
       "      <td>...</td>\n",
       "      <td>2739</td>\n",
       "      <td>2238</td>\n",
       "      <td>2189</td>\n",
       "      <td>3014</td>\n",
       "      <td>1403</td>\n",
       "      <td>2306</td>\n",
       "      <td>883</td>\n",
       "      <td>632</td>\n",
       "      <td>489</td>\n",
       "      <td>2647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GEO_ID                     NAME total_pop pop_0_5 pop_5_10  \\\n",
       "1  0500000US01003  Baldwin County, Alabama    223234   10616    12826   \n",
       "2  0500000US01015  Calhoun County, Alabama    113605    6699     5534   \n",
       "3  0500000US01043  Cullman County, Alabama     83768    5310     4563   \n",
       "4  0500000US01049   DeKalb County, Alabama     71513    4578     4292   \n",
       "5  0500000US01051   Elmore County, Alabama     81209    4272     6638   \n",
       "\n",
       "  pop_10_15 pop_15_20 pop_20_25 pop_25_30 pop_30_35  ... pop_male_45_50  \\\n",
       "1     14373     14410     11292     11807     12594  ...           6458   \n",
       "2      7774      7541      6973      7088      7893  ...           3160   \n",
       "3      5906      4591      4603      5402      5186  ...           2889   \n",
       "4      5519      5128      4989      4281      4155  ...           2185   \n",
       "5      3812      4896      4038      6165      6956  ...           2739   \n",
       "\n",
       "  pop_male_50_55 pop_male_55_60 pop_male_60_65 pop_male_65_70 pop_male_70_75  \\\n",
       "1           6270           7620           7644           6084           7170   \n",
       "2           3032           3164           4281           2683           2658   \n",
       "3           2662           2279           3170           1673           2596   \n",
       "4           2203           2011           2388           2080           1281   \n",
       "5           2238           2189           3014           1403           2306   \n",
       "\n",
       "  pop_male_75_80 pop_male_80_85 pop_male_85_90 pop_male_105_110  \n",
       "1           3677           2851           1791             8068  \n",
       "2           1541            960            901             4245  \n",
       "3           1411            593            661             2962  \n",
       "4           1476            437             85             3956  \n",
       "5            883            632            489             2647  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp=pd.read_csv('./demographics/dp_2016.csv')\n",
    "valid_columns=['GEO_ID','NAME','DP05_0033E','DP05_0034E','DP05_0039E','DP05_0066E','DP05_0032E','DP05_0028E']\n",
    "dp_vc=dp.loc[:,valid_columns]\n",
    "dp_vc.rename(axis=1,mapper={'DP05_0033E':'afr_amer','DP05_0034E':'amer_ind','DP05_0039E':'asian','DP05_0066E':'latino','DP05_0032E':'white','DP05_0028E':'tot_pop'},inplace=True)\n",
    "dp_vc=dp_vc.loc[1:]\n",
    "dp_vc.replace(to_replace='N',value=0,inplace=True)\n",
    "for x in dp_vc.columns:\n",
    "    if x!='NAME' and x!='GEO_ID':\n",
    "        dp_vc[x]=dp_vc[x].apply(int)\n",
    "dp_vc.to_csv('./demographics/dp_2016_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp=pd.read_csv('./demographics/dp_2019.csv')\n",
    "valid_columns=['GEO_ID','NAME','DP05_0038E','DP05_0039E','DP05_0044E','DP05_0071E','DP05_0037E','DP05_0033E']\n",
    "dp_vc=dp.loc[:,valid_columns]\n",
    "dp_vc.rename(axis=1,mapper={'DP05_0038E':'afr_amer','DP05_0039E':'amer_ind','DP05_0044E':'asian','DP05_0071E':'latino','DP05_0037E':'white','DP05_0033E':'tot_pop'},inplace=True)\n",
    "dp_vc=dp_vc.loc[1:]\n",
    "dp_vc.replace(to_replace='N',value=0,inplace=True)\n",
    "for x in dp_vc.columns:\n",
    "    if x!='NAME' and x!='GEO_ID':\n",
    "        dp_vc[x]=dp_vc[x].apply(int)\n",
    "dp_vc.to_csv('./demographics/dp_2019_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleanup Poverty Data\n",
    "\n",
    "#poverty=pd.read_csv('./poverty/poverty_2019.csv')\n",
    "#valid_columns=['GEO_ID','NAME','S1701_C01_001E','S1701_C01_006E','S1701_C01_010E','S1701_C01_040E']\n",
    "#poverty_vc=poverty.loc[:,valid_columns]\n",
    "#poverty_vc.rename(axis=1,mapper={'S1701_C01_001E':'tot_poverty','S1701_C01_006E':'pov_18_64','S1701_C01_010E':'pov_65_up','S1701_C01_040E':'pov_150'},inplace=True)\n",
    "#poverty_vc=poverty_vc.loc[1:]\n",
    "#for x in poverty_vc.columns:\n",
    "#    if x!='NAME' and x!='GEO_ID':\n",
    "#        poverty_vc[x]=poverty_vc[x].apply(int)\n",
    "#    #poverty_vc['tot_poverty'].apply(int)\n",
    "#poverty_vc['pov_18_up']=poverty_vc['pov_18_64']+poverty_vc['pov_65_up']\n",
    "#poverty_vc.to_csv('./poverty/poverty_2019_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#income=pd.read_csv('./income/income_2019.csv')\n",
    "#valid_columns=['GEO_ID','NAME','DP03_0009PE','DP03_0062E','DP03_0063E']\n",
    "#income_vc=income.loc[:,valid_columns]\n",
    "#income_vc.rename(axis=1,mapper={'DP03_0009PE':'unemp_rate','DP03_0062E':'med_hh_inc','DP03_0063E':'mean_hh_inc'},inplace=True)\n",
    "#income_vc=income_vc.loc[1:]\n",
    "#income_vc.replace(to_replace='N',value=0,inplace=True)\n",
    "#for x in income_vc.columns:\n",
    "#    if x!='NAME' and x!='GEO_ID':\n",
    "#        income_vc[x]=income_vc[x].apply(float)\n",
    "#income_vc.to_csv('./income/income_2019_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
