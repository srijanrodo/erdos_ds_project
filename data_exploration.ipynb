{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from pathlib import Path\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_trump=pd.read_csv('./tweet_data/trump.csv',engine='python')\n",
    "#tweets_biden=pd.read_csv('./tweet_data/biden.csv')\n",
    "#tjb=tweets_biden.dropna(subset=['lat','long','city','state','user_location'],how='all')\n",
    "#tdt=tweets_trump.dropna(subset=['lat','long','city','state','user_location'],how='all')\n",
    "#tjb=tjb.loc[(tjb['country']==\"United States\" ) | (tjb['country']==\"United States of America\")]\n",
    "#tdt=tdt.loc[(tdt['country']==\"United States\" ) | (tdt['country']==\"United States of America\")]\n",
    "#photon_url=\"http://localhost:2322/api?q=\"\n",
    "#photon_reverse=\"http://localhost:2322/reverse?\"\n",
    "\n",
    "#tjb['query_url']=pd.NA\n",
    "#for x in tjb.index:\n",
    "#    if pd.notna(tjb.loc[x,'lat']) and pd.notna(tjb.loc[x,'long']):\n",
    "#        tjb.loc[x,'query_url']=photon_reverse+'lat='+str(tjb.loc[x,'lat'])+'&'+'lon='+str(tjb.loc[x,'long'])\n",
    "#    elif pd.notna(tjb.loc[x,'city']) and pd.notna(tjb.loc[x,'state']):\n",
    "#        tjb.loc[x,'query_url']=photon_url+ tjb.loc[x,'city']+ ' ' + tjb.loc[x,'state']\n",
    "#    else:\n",
    "#        tjb.loc[x,'query_url']=photon_url+str(tjb.loc[x,'user_location'])\n",
    "#tjb['county']=pd.NA\n",
    "#i=0\n",
    "#j=0\n",
    "#for x in tjb.index:\n",
    "#    try:\n",
    "#        photon_response=requests.get(tjb.loc[x,'query_url']).json()['features'][0]['properties']['county']\n",
    "        #j=j+1\n",
    "#    except:\n",
    "#        photon_response=pd.NA\n",
    "#    tjb.loc[x,'county'] = photon_response\n",
    "    #i=i+1\n",
    "    #print(i,j)\n",
    "    #tdt['query_url']=pd.NA\n",
    "#for x in tdt.index:\n",
    "#    if pd.notna(tdt.loc[x,'lat']) and pd.notna(tdt.loc[x,'long']):\n",
    "#        tdt.loc[x,'query_url']=photon_reverse+'lat='+str(tdt.loc[x,'lat'])+'&'+'lon='+str(tdt.loc[x,'long'])\n",
    "#    elif pd.notna(tjb.loc[x,'city']) and pd.notna(tdt.loc[x,'state']):\n",
    "#        tdt.loc[x,'query_url']=photon_url+ tdt.loc[x,'city']+ ' ' + tdt.loc[x,'state']\n",
    "#    else:\n",
    "#        tdt.loc[x,'query_url']=photon_url+str(tdt.loc[x,'user_location'])\n",
    "#tdt['county']=pd.NA\n",
    "#i=0\n",
    "#j=0\n",
    "#for x in tdt.index:\n",
    "#    try:\n",
    "#        photon_response=requests.get(tdt.loc[x,'query_url']).json()['features'][0]['properties']['county']\n",
    "#        j=j+1\n",
    "#    except:\n",
    "#        photon_response=pd.NA\n",
    "#    tdt.loc[x,'county'] = photon_response\n",
    "#    i=i+1\n",
    "#    print(i,j)\n",
    "#filepath=Path('./tweet_data/biden_countied.csv')\n",
    "#tjb.to_csv(filepath)\n",
    "#filepath=Path('./tweet_data/trump_countied.csv')\n",
    "#tdt.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the files\n",
    "#tweets_biden=pd.read_csv('./tweet_data/biden_countied.csv')\n",
    "#tweets_trump=pd.read_csv('./tweet_data/trump_countied.csv')\n",
    "#Only consider those with a valid county and cut down on not needed columns\n",
    "#valid_tweets_b=tweets_biden.dropna(subset=['county']).drop(axis=1,labels=['lat','long','city','country','continent','state','collected_at','user_screen_name','user_name','source','tweet_id','query_url','user_join_date','Unnamed: 0'])\n",
    "#valid_tweets_t=tweets_trump.dropna(subset=['county']).drop(axis=1,labels=['lat','long','city','country','continent','state','collected_at','user_screen_name','user_name','source','tweet_id','query_url','user_join_date','Unnamed: 0'])\n",
    "#valid_tweets=pd.concat([valid_tweets_b,valid_tweets_t], ignore_index=True)\n",
    "#valid_tweets.to_csv('./tweet_data/valid_tweets.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is some boilerplate code to cleanup and name the dataset from census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demographics=pd.read_csv('./demographics/demographics.csv')\n",
    "#tmp_in=pd.Series(range(1,39)).apply(str).apply(lambda x:x.zfill(3))\n",
    "#columns_to_drop1=[x+y+z for x in ('S0101_C'+pd.Series(['02','04','05','06'])+'_') for y in tmp_in for z in ['E','M']]\n",
    "#columns_to_drop2=[x+y+z for x in ('S0101_C'+pd.Series(['01','03'])+'_') for y in tmp_in for z in ['M']]\n",
    "#ttmp_in=pd.Series(range(20,39)).apply(str).apply(lambda x:x.zfill(3))\n",
    "#columns_to_drop3=[x+y+z for x in ('S0101_C'+pd.Series(['01','03'])+'_') for y in ttmp_in for z in ['E']]\n",
    "#columns_to_drop=columns_to_drop1+columns_to_drop2+columns_to_drop3+['Unnamed: 458']\n",
    "#().apply(lambda x:x+tmp_in+'E')\n",
    "#len(columns_to_drop)\n",
    "#demographics=demographics.drop(axis=1,labels=columns_to_drop)\n",
    "#def convert_column_names(x):\n",
    "#    x_split = x.split('_')\n",
    "#    if len(x_split)!=3:\n",
    "#        return x\n",
    "#    if x_split[1]=='C01':\n",
    "#        i=int(x_split[2][:-1])\n",
    "#        if i==1:\n",
    "#            return 'total_pop'\n",
    "#        return 'pop_'+str((i-2)*5)+'_'+str((i-1)*5)\n",
    "#    if x_split[1]=='C03':\n",
    "#        i=int(x_split[2][:-1])\n",
    "#        if i==1:\n",
    "#            return 'total_male_pop'\n",
    "#        return 'pop_male_'+str((i-2)*5)+'_'+str((i-1)*5)\n",
    "    \n",
    "#demographics.rename(axis=1,mapper=convert_column_names,inplace=True)\n",
    "#demographics=demographics.loc[1:]\n",
    "#demographics.to_csv('./demographics/demographics_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dp=pd.read_csv('./demographics/dp_2016.csv')\n",
    "#valid_columns=['GEO_ID','NAME','DP05_0038E','DP05_0039E','DP05_0044E','DP05_0071E','DP05_0064E']\n",
    "#dp_vc=dp.loc[:,valid_columns]\n",
    "#dp_vc.rename(axis=1,mapper={'DP05_0038E':'afr_amer','DP05_0039E':'amer_ind','DP05_0044E':'asian','DP05_0071E':'latino','DP05_0064E':'white'},inplace=True)\n",
    "#dp_vc=dp_vc.loc[1:]\n",
    "#dp_vc.replace(to_replace='N',value=0,inplace=True)\n",
    "#for x in dp_vc.columns:\n",
    "#    if x!='NAME' and x!='GEO_ID':\n",
    "#        dp_vc[x]=dp_vc[x].apply(int)\n",
    "##poverty_vc['pov_18_up']=poverty_vc['pov_18_64']+poverty_vc['pov_65_up']\n",
    "#dp_vc.to_csv('./demographics/dp_2016_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleanup Poverty Data\n",
    "\n",
    "#poverty=pd.read_csv('./poverty/poverty_2019.csv')\n",
    "#valid_columns=['GEO_ID','NAME','S1701_C01_001E','S1701_C01_006E','S1701_C01_010E','S1701_C01_040E']\n",
    "#poverty_vc=poverty.loc[:,valid_columns]\n",
    "#poverty_vc.rename(axis=1,mapper={'S1701_C01_001E':'tot_poverty','S1701_C01_006E':'pov_18_64','S1701_C01_010E':'pov_65_up','S1701_C01_040E':'pov_150'},inplace=True)\n",
    "#poverty_vc=poverty_vc.loc[1:]\n",
    "#for x in poverty_vc.columns:\n",
    "#    if x!='NAME' and x!='GEO_ID':\n",
    "#        poverty_vc[x]=poverty_vc[x].apply(int)\n",
    "#    #poverty_vc['tot_poverty'].apply(int)\n",
    "#poverty_vc['pov_18_up']=poverty_vc['pov_18_64']+poverty_vc['pov_65_up']\n",
    "#poverty_vc.to_csv('./poverty/poverty_2019_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GEO_ID                                              Geography\n",
       "NAME                                     Geographic Area Name\n",
       "afr_amer    Estimate!!RACE!!Total population!!One race!!Bl...\n",
       "amer_ind    Estimate!!RACE!!Total population!!One race!!Am...\n",
       "asian       Estimate!!RACE!!Total population!!One race!!Asian\n",
       "latino      Estimate!!HISPANIC OR LATINO AND RACE!!Total p...\n",
       "white       Estimate!!Race alone or in combination with on...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_vc.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>afr_amer</th>\n",
       "      <th>amer_ind</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0500000US01003</td>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>18338</td>\n",
       "      <td>2428</td>\n",
       "      <td>2160</td>\n",
       "      <td>10534</td>\n",
       "      <td>195623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0500000US01015</td>\n",
       "      <td>Calhoun County, Alabama</td>\n",
       "      <td>25226</td>\n",
       "      <td>201</td>\n",
       "      <td>225</td>\n",
       "      <td>4614</td>\n",
       "      <td>84545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0500000US01043</td>\n",
       "      <td>Cullman County, Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3752</td>\n",
       "      <td>81716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0500000US01049</td>\n",
       "      <td>DeKalb County, Alabama</td>\n",
       "      <td>688</td>\n",
       "      <td>792</td>\n",
       "      <td>17</td>\n",
       "      <td>10775</td>\n",
       "      <td>61350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0500000US01051</td>\n",
       "      <td>Elmore County, Alabama</td>\n",
       "      <td>17768</td>\n",
       "      <td>204</td>\n",
       "      <td>884</td>\n",
       "      <td>2563</td>\n",
       "      <td>62137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           GEO_ID                     NAME  afr_amer  amer_ind  asian  latino  \\\n",
       "1  0500000US01003  Baldwin County, Alabama     18338      2428   2160   10534   \n",
       "2  0500000US01015  Calhoun County, Alabama     25226       201    225    4614   \n",
       "3  0500000US01043  Cullman County, Alabama         0         0      0    3752   \n",
       "4  0500000US01049   DeKalb County, Alabama       688       792     17   10775   \n",
       "5  0500000US01051   Elmore County, Alabama     17768       204    884    2563   \n",
       "\n",
       "    white  \n",
       "1  195623  \n",
       "2   84545  \n",
       "3   81716  \n",
       "4   61350  \n",
       "5   62137  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_vc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
