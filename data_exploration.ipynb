{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from pathlib import Path\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_trump=pd.read_csv('./tweet_data/trump.csv',engine='python')\n",
    "#tweets_biden=pd.read_csv('./tweet_data/biden.csv')\n",
    "#tjb=tweets_biden.dropna(subset=['lat','long','city','state','user_location'],how='all')\n",
    "#tdt=tweets_trump.dropna(subset=['lat','long','city','state','user_location'],how='all')\n",
    "#tjb=tjb.loc[(tjb['country']==\"United States\" ) | (tjb['country']==\"United States of America\")]\n",
    "#tdt=tdt.loc[(tdt['country']==\"United States\" ) | (tdt['country']==\"United States of America\")]\n",
    "#photon_url=\"http://localhost:2322/api?q=\"\n",
    "#photon_reverse=\"http://localhost:2322/reverse?\"\n",
    "\n",
    "#tjb['query_url']=pd.NA\n",
    "#for x in tjb.index:\n",
    "#    if pd.notna(tjb.loc[x,'lat']) and pd.notna(tjb.loc[x,'long']):\n",
    "#        tjb.loc[x,'query_url']=photon_reverse+'lat='+str(tjb.loc[x,'lat'])+'&'+'lon='+str(tjb.loc[x,'long'])\n",
    "#    elif pd.notna(tjb.loc[x,'city']) and pd.notna(tjb.loc[x,'state']):\n",
    "#        tjb.loc[x,'query_url']=photon_url+ tjb.loc[x,'city']+ ' ' + tjb.loc[x,'state']\n",
    "#    else:\n",
    "#        tjb.loc[x,'query_url']=photon_url+str(tjb.loc[x,'user_location'])\n",
    "#tjb['county']=pd.NA\n",
    "#i=0\n",
    "#j=0\n",
    "#for x in tjb.index:\n",
    "#    try:\n",
    "#        photon_response=requests.get(tjb.loc[x,'query_url']).json()['features'][0]['properties']['county']\n",
    "        #j=j+1\n",
    "#    except:\n",
    "#        photon_response=pd.NA\n",
    "#    tjb.loc[x,'county'] = photon_response\n",
    "    #i=i+1\n",
    "    #print(i,j)\n",
    "    #tdt['query_url']=pd.NA\n",
    "#for x in tdt.index:\n",
    "#    if pd.notna(tdt.loc[x,'lat']) and pd.notna(tdt.loc[x,'long']):\n",
    "#        tdt.loc[x,'query_url']=photon_reverse+'lat='+str(tdt.loc[x,'lat'])+'&'+'lon='+str(tdt.loc[x,'long'])\n",
    "#    elif pd.notna(tjb.loc[x,'city']) and pd.notna(tdt.loc[x,'state']):\n",
    "#        tdt.loc[x,'query_url']=photon_url+ tdt.loc[x,'city']+ ' ' + tdt.loc[x,'state']\n",
    "#    else:\n",
    "#        tdt.loc[x,'query_url']=photon_url+str(tdt.loc[x,'user_location'])\n",
    "#tdt['county']=pd.NA\n",
    "#i=0\n",
    "#j=0\n",
    "#for x in tdt.index:\n",
    "#    try:\n",
    "#        photon_response=requests.get(tdt.loc[x,'query_url']).json()['features'][0]['properties']['county']\n",
    "#        j=j+1\n",
    "#    except:\n",
    "#        photon_response=pd.NA\n",
    "#    tdt.loc[x,'county'] = photon_response\n",
    "#    i=i+1\n",
    "#    print(i,j)\n",
    "#filepath=Path('./tweet_data/biden_countied.csv')\n",
    "#tjb.to_csv(filepath)\n",
    "#filepath=Path('./tweet_data/trump_countied.csv')\n",
    "#tdt.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the files\n",
    "tweets_biden=pd.read_csv('./tweet_data/biden_countied.csv')\n",
    "tweets_trump=pd.read_csv('./tweet_data/trump_countied.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only consider those with a valid county and cut down on not needed columns\n",
    "valid_tweets_b=tweets_biden.dropna(subset=['county']).drop(axis=1,labels=['lat','long','city','country','continent','state','collected_at','user_screen_name','user_name','source','tweet_id','query_url','user_join_date','Unnamed: 0'])\n",
    "valid_tweets_t=tweets_trump.dropna(subset=['county']).drop(axis=1,labels=['lat','long','city','country','continent','state','collected_at','user_screen_name','user_name','source','tweet_id','query_url','user_join_date','Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tweets=pd.concat([valid_tweets_b,valid_tweets_t], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 167063 entries, 0 to 167062\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   created_at            167063 non-null  object \n",
      " 1   tweet                 167063 non-null  object \n",
      " 2   likes                 167063 non-null  float64\n",
      " 3   retweet_count         167063 non-null  float64\n",
      " 4   user_id               167063 non-null  float64\n",
      " 5   user_description      157090 non-null  object \n",
      " 6   user_followers_count  167063 non-null  float64\n",
      " 7   user_location         167063 non-null  object \n",
      " 8   state_code            167062 non-null  object \n",
      " 9   county                167063 non-null  object \n",
      "dtypes: float64(4), object(6)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "valid_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
