{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from pathlib import Path\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_trump=pd.read_csv('./tweet_data/trump.csv',engine='python')\n",
    "#tweets_biden=pd.read_csv('./tweet_data/biden.csv')\n",
    "#tjb=tweets_biden.dropna(subset=['lat','long','city','state','user_location'],how='all')\n",
    "#tdt=tweets_trump.dropna(subset=['lat','long','city','state','user_location'],how='all')\n",
    "#tjb=tjb.loc[(tjb['country']==\"United States\" ) | (tjb['country']==\"United States of America\")]\n",
    "#tdt=tdt.loc[(tdt['country']==\"United States\" ) | (tdt['country']==\"United States of America\")]\n",
    "#photon_url=\"http://localhost:2322/api?q=\"\n",
    "#photon_reverse=\"http://localhost:2322/reverse?\"\n",
    "\n",
    "#tjb['query_url']=pd.NA\n",
    "#for x in tjb.index:\n",
    "#    if pd.notna(tjb.loc[x,'lat']) and pd.notna(tjb.loc[x,'long']):\n",
    "#        tjb.loc[x,'query_url']=photon_reverse+'lat='+str(tjb.loc[x,'lat'])+'&'+'lon='+str(tjb.loc[x,'long'])\n",
    "#    elif pd.notna(tjb.loc[x,'city']) and pd.notna(tjb.loc[x,'state']):\n",
    "#        tjb.loc[x,'query_url']=photon_url+ tjb.loc[x,'city']+ ' ' + tjb.loc[x,'state']\n",
    "#    else:\n",
    "#        tjb.loc[x,'query_url']=photon_url+str(tjb.loc[x,'user_location'])\n",
    "#tjb['county']=pd.NA\n",
    "#i=0\n",
    "#j=0\n",
    "#for x in tjb.index:\n",
    "#    try:\n",
    "#        photon_response=requests.get(tjb.loc[x,'query_url']).json()['features'][0]['properties']['county']\n",
    "        #j=j+1\n",
    "#    except:\n",
    "#        photon_response=pd.NA\n",
    "#    tjb.loc[x,'county'] = photon_response\n",
    "    #i=i+1\n",
    "    #print(i,j)\n",
    "    #tdt['query_url']=pd.NA\n",
    "#for x in tdt.index:\n",
    "#    if pd.notna(tdt.loc[x,'lat']) and pd.notna(tdt.loc[x,'long']):\n",
    "#        tdt.loc[x,'query_url']=photon_reverse+'lat='+str(tdt.loc[x,'lat'])+'&'+'lon='+str(tdt.loc[x,'long'])\n",
    "#    elif pd.notna(tjb.loc[x,'city']) and pd.notna(tdt.loc[x,'state']):\n",
    "#        tdt.loc[x,'query_url']=photon_url+ tdt.loc[x,'city']+ ' ' + tdt.loc[x,'state']\n",
    "#    else:\n",
    "#        tdt.loc[x,'query_url']=photon_url+str(tdt.loc[x,'user_location'])\n",
    "#tdt['county']=pd.NA\n",
    "#i=0\n",
    "#j=0\n",
    "#for x in tdt.index:\n",
    "#    try:\n",
    "#        photon_response=requests.get(tdt.loc[x,'query_url']).json()['features'][0]['properties']['county']\n",
    "#        j=j+1\n",
    "#    except:\n",
    "#        photon_response=pd.NA\n",
    "#    tdt.loc[x,'county'] = photon_response\n",
    "#    i=i+1\n",
    "#    print(i,j)\n",
    "#filepath=Path('./tweet_data/biden_countied.csv')\n",
    "#tjb.to_csv(filepath)\n",
    "#filepath=Path('./tweet_data/trump_countied.csv')\n",
    "#tdt.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the files\n",
    "#tweets_biden=pd.read_csv('./tweet_data/biden_countied.csv')\n",
    "#tweets_trump=pd.read_csv('./tweet_data/trump_countied.csv')\n",
    "#Only consider those with a valid county and cut down on not needed columns\n",
    "#valid_tweets_b=tweets_biden.dropna(subset=['county']).drop(axis=1,labels=['lat','long','city','country','continent','state','collected_at','user_screen_name','user_name','source','tweet_id','query_url','user_join_date','Unnamed: 0'])\n",
    "#valid_tweets_t=tweets_trump.dropna(subset=['county']).drop(axis=1,labels=['lat','long','city','country','continent','state','collected_at','user_screen_name','user_name','source','tweet_id','query_url','user_join_date','Unnamed: 0'])\n",
    "#valid_tweets=pd.concat([valid_tweets_b,valid_tweets_t], ignore_index=True)\n",
    "#valid_tweets.to_csv('./tweet_data/valid_tweets.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is some boilerplate code to cleanup and name the dataset from census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demographics=pd.read_csv('./demographics/demographics.csv')\n",
    "#tmp_in=pd.Series(range(1,39)).apply(str).apply(lambda x:x.zfill(3))\n",
    "#columns_to_drop1=[x+y+z for x in ('S0101_C'+pd.Series(['02','04','05','06'])+'_') for y in tmp_in for z in ['E','M']]\n",
    "#columns_to_drop2=[x+y+z for x in ('S0101_C'+pd.Series(['01','03'])+'_') for y in tmp_in for z in ['M']]\n",
    "#ttmp_in=pd.Series(range(20,39)).apply(str).apply(lambda x:x.zfill(3))\n",
    "#columns_to_drop3=[x+y+z for x in ('S0101_C'+pd.Series(['01','03'])+'_') for y in ttmp_in for z in ['E']]\n",
    "#columns_to_drop=columns_to_drop1+columns_to_drop2+columns_to_drop3+['Unnamed: 458']\n",
    "#().apply(lambda x:x+tmp_in+'E')\n",
    "#len(columns_to_drop)\n",
    "#demographics=demographics.drop(axis=1,labels=columns_to_drop)\n",
    "#def convert_column_names(x):\n",
    "#    x_split = x.split('_')\n",
    "#    if len(x_split)!=3:\n",
    "#        return x\n",
    "#    if x_split[1]=='C01':\n",
    "#        i=int(x_split[2][:-1])\n",
    "#        if i==1:\n",
    "#            return 'total_pop'\n",
    "#        return 'pop_'+str((i-2)*5)+'_'+str((i-1)*5)\n",
    "#    if x_split[1]=='C03':\n",
    "#        i=int(x_split[2][:-1])\n",
    "#        if i==1:\n",
    "#            return 'total_male_pop'\n",
    "#        return 'pop_male_'+str((i-2)*5)+'_'+str((i-1)*5)\n",
    "    \n",
    "#demographics.rename(axis=1,mapper=convert_column_names,inplace=True)\n",
    "#demographics=demographics.loc[1:]\n",
    "#demographics.to_csv('./demographics/demographics_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleanup Poverty Data\n",
    "\n",
    "#poverty=pd.read_csv('./poverty/poverty_2019.csv')\n",
    "#valid_columns=['GEO_ID','NAME','S1701_C01_001E','S1701_C01_006E','S1701_C01_010E','S1701_C01_040E']\n",
    "#poverty_vc=poverty.loc[:,valid_columns]\n",
    "#poverty_vc.rename(axis=1,mapper={'S1701_C01_001E':'tot_poverty','S1701_C01_006E':'pov_18_64','S1701_C01_010E':'pov_65_up','S1701_C01_040E':'pov_150'},inplace=True)\n",
    "#poverty_vc=poverty_vc.loc[1:]\n",
    "#for x in poverty_vc.columns:\n",
    "#    if x!='NAME' and x!='GEO_ID':\n",
    "#        poverty_vc[x]=poverty_vc[x].apply(int)\n",
    "#    #poverty_vc['tot_poverty'].apply(int)\n",
    "#poverty_vc['pov_18_up']=poverty_vc['pov_18_64']+poverty_vc['pov_65_up']\n",
    "#poverty_vc.to_csv('./poverty/poverty_2019_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>tot_poverty</th>\n",
       "      <th>pov_18_64</th>\n",
       "      <th>pov_65_up</th>\n",
       "      <th>pov_150</th>\n",
       "      <th>pov_18_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0500000US01003</td>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>219405</td>\n",
       "      <td>126865</td>\n",
       "      <td>46838</td>\n",
       "      <td>44984</td>\n",
       "      <td>173703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0500000US01015</td>\n",
       "      <td>Calhoun County, Alabama</td>\n",
       "      <td>110599</td>\n",
       "      <td>66508</td>\n",
       "      <td>20145</td>\n",
       "      <td>30186</td>\n",
       "      <td>86653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0500000US01043</td>\n",
       "      <td>Cullman County, Alabama</td>\n",
       "      <td>82575</td>\n",
       "      <td>48836</td>\n",
       "      <td>15046</td>\n",
       "      <td>16518</td>\n",
       "      <td>63882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0500000US01049</td>\n",
       "      <td>DeKalb County, Alabama</td>\n",
       "      <td>70682</td>\n",
       "      <td>41789</td>\n",
       "      <td>11511</td>\n",
       "      <td>20028</td>\n",
       "      <td>53300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0500000US01051</td>\n",
       "      <td>Elmore County, Alabama</td>\n",
       "      <td>76605</td>\n",
       "      <td>46324</td>\n",
       "      <td>12362</td>\n",
       "      <td>16230</td>\n",
       "      <td>58686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           GEO_ID                     NAME  tot_poverty  pov_18_64  pov_65_up  \\\n",
       "1  0500000US01003  Baldwin County, Alabama       219405     126865      46838   \n",
       "2  0500000US01015  Calhoun County, Alabama       110599      66508      20145   \n",
       "3  0500000US01043  Cullman County, Alabama        82575      48836      15046   \n",
       "4  0500000US01049   DeKalb County, Alabama        70682      41789      11511   \n",
       "5  0500000US01051   Elmore County, Alabama        76605      46324      12362   \n",
       "\n",
       "   pov_150  pov_18_up  \n",
       "1    44984     173703  \n",
       "2    30186      86653  \n",
       "3    16518      63882  \n",
       "4    20028      53300  \n",
       "5    16230      58686  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
